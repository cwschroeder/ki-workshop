/**
 * B2BUA Integration Test
 *
 * Testet die 3-Parteien-Konferenz mit simulierten SIP-Agents
 *
 * Setup:
 * 1. B2BUA Server (cwschroeder) - Empf√§ngt Calls und bridged
 * 2. Agent Simulator (pjschroeder) - Simulierte Stadtwerk-Hotline
 * 3. Customer Simulator (lkschroeder) - Simulierter Kunde, ruft an
 */

import { SIPServerService } from '../services/SIPServerService';
import { B2BUAManager } from '../services/B2BUAManager';
import { VoiceAgentPipeline } from '../services/VoiceAgentPipeline';
import { OpenAISTTProvider } from '../providers/openai/OpenAISTTProvider';
import { OpenAILLMProvider } from '../providers/openai/OpenAILLMProvider';
import { OpenAITTSProvider } from '../providers/openai/OpenAITTSProvider';
import { TranscriptVerifier } from './transcript-verifier';
import { TranscriptUpdateService } from '../services/TranscriptUpdateService';
import { TranscriptWebSocketServer } from '../websocket/TranscriptWebSocketServer';
import { VADBuffer } from '../services/VADBuffer';
import { env } from '../config/env';
import { logger } from '../utils/logger';

/**
 * Test Manager orchestriert alle drei Komponenten
 */
class B2BUATestManager {
  // B2BUA Server (cwschroeder)
  private b2buaServer: SIPServerService;
  private b2buaManager: B2BUAManager;

  // Agent Simulator (pjschroeder)
  private agentServer: SIPServerService;
  private agentPipeline: VoiceAgentPipeline | null = null;

  // Customer Simulator (lkschroeder)
  private customerServer: SIPServerService;
  private customerPipeline: VoiceAgentPipeline | null = null;

  // AI Providers
  private sttProvider: OpenAISTTProvider;
  private llmProvider: OpenAILLMProvider;
  private ttsProvider: OpenAITTSProvider;

  // Transcript Update & WebSocket
  private transcriptUpdates: TranscriptUpdateService;
  private transcriptWebSocket: TranscriptWebSocketServer;

  // Stats
  private transcriptCount = 0;
  private conferenceStartTime: number = 0;
  private customerTurnCount = 0;
  private currentSessionId: string = '';

  // Transcript Verification
  private transcriptVerifier: TranscriptVerifier | null = null;

  // VAD Buffers per session (for cleanup/flush on end)
  private vadBuffers: Map<string, { legA: VADBuffer; legB: VADBuffer }> = new Map();

  constructor() {
    logger.info('üß™ Initializing B2BUA Test Environment (Peer-to-Peer Mode)');

    // Initialize AI providers
    this.sttProvider = new OpenAISTTProvider(env.OPENAI_API_KEY);
    this.llmProvider = new OpenAILLMProvider(env.OPENAI_API_KEY, 'gpt-4o-mini');
    this.ttsProvider = new OpenAITTSProvider(env.OPENAI_API_KEY, 'tts-1', 'nova');

    // Peer-to-Peer Mode: All servers on localhost, no Tenios registration
    // Note: Each server uses different RTP port ranges to avoid conflicts
    // 1. B2BUA Server (port 5060, RTP 10000-12000)
    this.b2buaServer = new SIPServerService(
      5060,
      'b2bua',
      'localhost',
      '',
      undefined,
      true  // skipRegistration = true
    );
    (this.b2buaServer as any).rtpPortRange = { min: 10000, max: 12000 };
    (this.b2buaServer as any).nextRTPPort = 10000;

    this.b2buaManager = new B2BUAManager(this.b2buaServer);

    // 2. Agent Simulator (port 5061, RTP 12000-14000)
    this.agentServer = new SIPServerService(
      5061,
      'agent',
      'localhost',
      '',
      undefined,
      true  // skipRegistration = true
    );
    (this.agentServer as any).rtpPortRange = { min: 12000, max: 14000 };
    (this.agentServer as any).nextRTPPort = 12000;

    // 3. Customer Simulator (port 5062, RTP 14000-16000)
    this.customerServer = new SIPServerService(
      5062,
      'customer',
      'localhost',
      '',
      undefined,
      true  // skipRegistration = true
    );
    (this.customerServer as any).rtpPortRange = { min: 14000, max: 16000 };
    (this.customerServer as any).nextRTPPort = 14000;

    // 4. Transcript Update Service (merges interim + final transcripts)
    this.transcriptUpdates = new TranscriptUpdateService();
    this.transcriptWebSocket = new TranscriptWebSocketServer(env.TRANSCRIPT_WS_PORT);

    // Listen for transcript updates and broadcast via WebSocket
    this.transcriptUpdates.on('update', (update) => {
      logger.info({
        sessionId: update.sessionId,
        speaker: update.speaker,
        revision: update.revision,
        status: update.status,
        text: update.text
      }, update.status === 'final' ? 'üí¨ Transcript final' : 'üîÑ Transcript update');

      this.transcriptWebSocket.broadcast(update);
    });

    logger.info({ wsPort: env.TRANSCRIPT_WS_PORT }, 'üì° Transcript WebSocket enabled');
  }

  async start(): Promise<void> {
    logger.info('üöÄ Starting B2BUA Test Environment');

    // Start B2BUA Server
    await this.setupB2BUAServer();

    // Start Agent Simulator
    await this.setupAgentSimulator();

    // Start Customer Simulator
    await this.setupCustomerSimulator();

    logger.info('‚úÖ Test Environment Ready');
    logger.info('');
    logger.info('üìã Test Setup (Peer-to-Peer):');
    logger.info('   1. B2BUA Server: localhost:5060');
    logger.info('   2. Agent Simulator: localhost:5061');
    logger.info('   3. Customer Simulator: localhost:5062');
    logger.info('');
    logger.info('üé¨ Test Scenario:');
    logger.info('   - Customer calls B2BUA directly (no Tenios routing)');
    logger.info('   - B2BUA bridges to Agent');
    logger.info('   - Agent responds with voice agent pipeline');
    logger.info('   - Both sides will be transcribed separately');
    logger.info('');
    logger.info('‚è∞ Automated test will start in 5 seconds...');
    logger.info('');

    // Auto-start test after 5 seconds
    setTimeout(() => {
      this.initiateTestCall();
    }, 5000);
  }

  private async setupB2BUAServer(): Promise<void> {
    logger.info('üîß Setting up B2BUA Server...');

    // Handle incoming calls -> automatically bridge to agent
    this.b2buaServer.on('callStarted', async ({ callId, rtpHandler }) => {
      // Only bridge inbound calls, not outbound calls we initiate
      const call = (this.b2buaServer as any).activeCalls.get(callId);
      if (!call || call.direction !== 'inbound') {
        return; // Skip outbound calls
      }

      // Check if session already exists for this call
      if (this.b2buaManager.getSessionByInboundCallId(callId)) {
        logger.debug({ callId }, 'Session already exists for this call, skipping');
        return;
      }

      logger.info({ callId }, 'üìû INCOMING CALL to B2BUA');

      try {
        // Create B2BUA session (bridge to agent on localhost:5061)
        const sessionId = await this.b2buaManager.createSession(callId, {
          destinationUri: 'sip:agent@192.168.188.86:5061',
          displayName: 'Test Customer',
          enableTranscription: true
        });

        logger.info({ sessionId, callId }, 'üîó B2BUA SESSION CREATED');
        this.conferenceStartTime = Date.now();

      } catch (error) {
        logger.error({ error, callId }, '‚ùå Failed to create B2BUA session');
      }
    });

    // Handle B2BUA events
    this.b2buaManager.on('sessionEstablished', ({ sessionId }) => {
      const duration = Date.now() - this.conferenceStartTime;
      logger.info({ sessionId, setupDurationMs: duration }, '‚úÖ CONFERENCE ESTABLISHED');

      // Track current session ID for transcript updates
      this.currentSessionId = sessionId;

      // Initialize transcript verifier for this session
      this.transcriptVerifier = new TranscriptVerifier(sessionId);

      this.setupTranscription(sessionId);
    });

    this.b2buaManager.on('sessionTerminated', ({ sessionId }) => {
      const duration = Date.now() - this.conferenceStartTime;
      logger.info({
        sessionId,
        durationMs: duration,
        transcriptCount: this.transcriptCount
      }, 'üîö CONFERENCE ENDED');

      // Generate verification report
      if (this.transcriptVerifier) {
        this.generateVerificationReport();
      }

      // Reset counters
      this.transcriptCount = 0;
      this.conferenceStartTime = 0;
      this.customerTurnCount = 0;
      this.transcriptVerifier = null;
    });

    await this.b2buaServer.start();
    logger.info('‚úÖ B2BUA Server started on port 5060');
  }

  private async setupAgentSimulator(): Promise<void> {
    logger.info('üîß Setting up Agent Simulator (pjschroeder)...');

    // When agent receives a call, start voice pipeline
    this.agentServer.on('callStarted', async ({ callId, rtpHandler }) => {
      logger.info({ callId }, 'üìû AGENT RECEIVED CALL');

      // Create interactive voice agent for the agent side
      // IMPORTANT: speakerLabel identifies WHO IS SPEAKING (the remote party being heard)
      // Agent pipeline hears the CUSTOMER speaking, so speakerLabel = 'customer'
      this.agentPipeline = new VoiceAgentPipeline(
        callId,
        rtpHandler,
        this.sttProvider,
        this.llmProvider,
        this.ttsProvider,
        {
          listenOnlyMode: false, // Agent responds interactively
          speakerLabel: 'customer' // Agent hears the Customer speaking
        }
      );

      // Listen for agent transcriptions (what agent hears)
      this.agentPipeline.on('transcription', (data) => {
        this.transcriptCount++;
        logger.info({
          speaker: data.speaker,
          text: data.text,
          count: this.transcriptCount,
          source: 'AGENT-H√ñRT'
        }, 'üéß [AGENT H√ñRT] üí¨');

        // Record in transcript verifier (for test verification only, NOT WebSocket)
        if (this.transcriptVerifier) {
          this.transcriptVerifier.addTranscript({
            source: 'AGENT-H√ñRT',
            speaker: data.speaker,
            text: data.text
          });
        }
      });

      // Listen for agent responses (what agent says)
      this.agentPipeline.on('agentResponse', (data) => {
        logger.info({
          speaker: 'agent',  // Agent is speaking, not customer!
          text: data.text,
          source: 'AGENT-SAGT'
        }, 'üó£Ô∏è  [AGENT SAGT] üí¨');

        // Ingest into transcript update service for real-time updates
        this.transcriptUpdates.ingest({
          sessionId: this.currentSessionId,
          speaker: 'agent',  // Agent is speaking
          text: data.text,
          timestamp: data.timestamp,
          source: 'AGENT-SAGT'
        });

        // Record in transcript verifier
        if (this.transcriptVerifier) {
          this.transcriptVerifier.addTranscript({
            source: 'AGENT-SAGT',
            speaker: 'agent',  // Agent is speaking
            text: data.text
          });
        }
      });

      // Audio flow logging disabled to reduce log spam
      // rtpHandler.on('audio', (audioData) => {
      //   // This is audio the agent receives (customer via B2BUA)
      //   logger.debug({
      //     source: 'AGENT-EMPF√ÑNGT',
      //     bytes: audioData.length,
      //     direction: 'Customer ‚Üí B2BUA ‚Üí Agent'
      //   }, 'üì° [AGENT EMPF√ÑNGT AUDIO]');
      // });

      await this.agentPipeline.start();
      logger.info({ callId }, 'üé§ Agent pipeline started');
    });

    this.agentServer.on('callEnded', async ({ callId }) => {
      logger.info({ callId }, 'üì¥ AGENT CALL ENDED');
      if (this.agentPipeline) {
        await this.agentPipeline.stop();
        this.agentPipeline = null;
      }
    });

    await this.agentServer.start();
    logger.info('‚úÖ Agent Simulator started on port 5061');
  }

  private setupTranscription(sessionId: string): void {
    const session = this.b2buaManager.getSession(sessionId);
    if (!session) return;

    logger.info({ sessionId }, 'üéôÔ∏è Setting up transcription for both legs via mixer');

    // Get the mixer from the session
    const mixer = (session as any).mixer;
    if (!mixer) {
      logger.error({ sessionId }, 'Mixer not found in session');
      return;
    }

    // VAD Buffers for each leg (Voice Activity Detection)
    // Automatically detects speech pauses and emits complete utterances
    const legAVAD = new VADBuffer(sessionId, {
      sampleRate: 8000,
      silenceThresholdDb: -40,     // -40dB threshold for silence
      silenceDurationMs: 500,      // 500ms of silence = end of utterance
      minUtteranceDurationMs: 500, // Minimum 500ms to avoid noise
      maxUtteranceDurationMs: 10000 // Max 10 seconds (force flush)
    });

    // Leg B (agent speech) - more tolerant to pauses to avoid splitting TTS-generated speech
    const legBVAD = new VADBuffer(sessionId, {
      sampleRate: 8000,
      silenceThresholdDb: -45,      // More sensitive threshold (-45dB instead of -40dB)
      silenceDurationMs: 1500,      // 1.5s of silence to allow natural pauses between sentences
      minUtteranceDurationMs: 500,  // Minimum 500ms to avoid noise
      maxUtteranceDurationMs: 15000 // Max 15 seconds (longer for multi-sentence agent responses)
    });

    // Listen for complete utterances from Leg A (customer) VAD
    legAVAD.on('utterance', async (pcmData: Buffer) => {
      try {
        // Transcribe PCM audio (provider will handle WAV conversion)
        const text = await this.sttProvider.transcribe(
          pcmData,  // Raw PCM data
          8000,     // Sample rate (G.711 is 8kHz)
          'de'      // German language
        );

        if (text && text.trim().length > 0) {
          this.transcriptCount++;
          logger.info({
            speaker: 'customer',
            text,
            count: this.transcriptCount,
            source: 'B2BUA-LEG-A'
          }, 'üéß [B2BUA H√ñRT CUSTOMER] üí¨');

          // Ingest into transcript update service for real-time updates
          this.transcriptUpdates.ingest({
            sessionId: this.currentSessionId,
            speaker: 'customer',
            text,
            timestamp: new Date(),
            source: 'B2BUA-LEG-A'
          });

          if (this.transcriptVerifier) {
            this.transcriptVerifier.addTranscript({
              source: 'B2BUA-LEG-A',
              speaker: 'customer',
              text
            });
          }
        }
      } catch (error) {
        logger.error({ error }, 'Failed to transcribe Leg A audio');
      }
    });

    // Listen for complete utterances from Leg B (agent) VAD
    legBVAD.on('utterance', async (pcmData: Buffer) => {
      try {
        // Transcribe PCM audio (provider will handle WAV conversion)
        const text = await this.sttProvider.transcribe(
          pcmData,  // Raw PCM data
          8000,     // Sample rate (G.711 is 8kHz)
          'de'      // German language
        );

        if (text && text.trim().length > 0) {
          this.transcriptCount++;
          logger.info({
            speaker: 'agent',
            text,
            count: this.transcriptCount,
            source: 'B2BUA-LEG-B'
          }, 'üéß [B2BUA H√ñRT AGENT] üí¨');

          // Ingest into transcript update service for real-time updates
          this.transcriptUpdates.ingest({
            sessionId: this.currentSessionId,
            speaker: 'agent',
            text,
            timestamp: new Date(),
            source: 'B2BUA-LEG-B'
          });

          if (this.transcriptVerifier) {
            this.transcriptVerifier.addTranscript({
              source: 'B2BUA-LEG-B',
              speaker: 'agent',
              text
            });
          }
        }
      } catch (error) {
        logger.error({ error }, 'Failed to transcribe Leg B audio');
      }
    });

    // Feed audio packets into VAD buffers
    mixer.on('legAAudio', (audioData: Buffer) => {
      legAVAD.ingest(audioData);
    });

    mixer.on('legBAudio', (audioData: Buffer) => {
      legBVAD.ingest(audioData);
    });

    // Store VAD buffers for cleanup/flush on session end
    this.vadBuffers.set(sessionId, { legA: legAVAD, legB: legBVAD });

    logger.info({ sessionId }, '‚úÖ Mixer transcription listeners attached');
  }

  private async setupCustomerSimulator(): Promise<void> {
    logger.info('üîß Setting up Customer Simulator (lkschroeder)...');

    // When customer's call is established, start voice pipeline
    this.customerServer.on('callStarted', async ({ callId, rtpHandler }) => {
      logger.info({ callId }, 'üìû CUSTOMER CALL ESTABLISHED');

      // Create voice pipeline for customer
      // IMPORTANT: speakerLabel identifies WHO IS SPEAKING (the remote party being heard)
      // Customer pipeline hears the AGENT speaking, so speakerLabel = 'agent'
      this.customerPipeline = new VoiceAgentPipeline(
        callId,
        rtpHandler,
        this.sttProvider,
        this.llmProvider,
        this.ttsProvider,
        {
          listenOnlyMode: false, // Customer speaks interactively
          speakerLabel: 'agent', // Customer hears the Agent speaking
          systemPrompt: `Du bist ein Kunde des Stadtwerks.
Du m√∂chtest deinen Z√§hlerstand melden.
Antworte kurz und nat√ºrlich auf Deutsch (max 1-2 S√§tze).
Verhalte dich wie ein normaler Kunde am Telefon.`,
          skipGreeting: true // Customer waits for agent to greet first
        }
      );

      // Listen for customer transcriptions (what customer hears from agent)
      this.customerPipeline.on('transcription', (data) => {
        this.transcriptCount++;
        logger.info({
          speaker: data.speaker,
          text: data.text,
          count: this.transcriptCount,
          source: 'CUSTOMER-H√ñRT'
        }, 'üéß [CUSTOMER H√ñRT AGENT] üí¨');

        // Record in transcript verifier (for test verification only, NOT WebSocket)
        if (this.transcriptVerifier) {
          this.transcriptVerifier.addTranscript({
            source: 'CUSTOMER-H√ñRT',
            speaker: data.speaker,
            text: data.text
          });
        }

        // Customer responds on turns (Turn 1: after hearing 'helfen', Turn 2: after response)
        if (this.customerTurnCount === 0 && data.text.includes('helfen')) {
          this.customerTurnCount++;
          setTimeout(async () => {
            const customerMessage = 'Ich m√∂chte meinen Z√§hlerstand melden';
            logger.info({ text: customerMessage, turn: 1 }, 'üó£Ô∏è Customer speaking (Turn 1)');

            try {
              // Generate TTS audio directly (returns PCM)
              const audioBuffer = await this.ttsProvider.synthesize(customerMessage, 'de');

              // Send via RTP in 20ms chunks (for VAD detection)
              await this.sendAudioInChunks(rtpHandler, audioBuffer);

              // Record the transcript manually since we're bypassing the pipeline
              this.transcriptCount++;

              // Record in transcript verifier (for test verification only, NOT WebSocket)
              if (this.transcriptVerifier) {
                this.transcriptVerifier.addTranscript({
                  source: 'CUSTOMER-SAGT',
                  speaker: 'customer',
                  text: customerMessage
                });
              }
              logger.info({ text: customerMessage, source: 'CUSTOMER-SAGT', turn: 1 }, 'üó£Ô∏è [CUSTOMER SAGT] üí¨ (Turn 1)');
            } catch (error) {
              logger.error({ error }, 'Failed to generate customer speech (Turn 1)');
            }
          }, 500); // Wait 500ms before responding
        }

        // Customer Turn 2: Responds again after agent's follow-up
        if (this.customerTurnCount === 1 && (data.text.includes('Z√§hlerstand') || data.text.includes('Z√§hlernummer'))) {
          this.customerTurnCount++;
          setTimeout(async () => {
            const customerMessage = 'Der Z√§hlerstand ist 4782';
            logger.info({ text: customerMessage, turn: 2 }, 'üó£Ô∏è Customer speaking (Turn 2)');

            try {
              // Generate TTS audio directly (returns PCM)
              const audioBuffer = await this.ttsProvider.synthesize(customerMessage, 'de');

              // Send via RTP in 20ms chunks (for VAD detection)
              await this.sendAudioInChunks(rtpHandler, audioBuffer);

              // Record the transcript manually
              this.transcriptCount++;

              // Ingest into transcript update service for real-time WebSocket updates
              this.transcriptUpdates.ingest({
                sessionId: this.currentSessionId,
                speaker: 'customer',
                text: customerMessage,
                timestamp: new Date(),
                source: 'CUSTOMER-SAGT',
                isFinal: true  // Mark as final so it broadcasts immediately
              });

              if (this.transcriptVerifier) {
                this.transcriptVerifier.addTranscript({
                  source: 'CUSTOMER-SAGT',
                  speaker: 'customer',
                  text: customerMessage
                });
              }
              logger.info({ text: customerMessage, source: 'CUSTOMER-SAGT', turn: 2 }, 'üó£Ô∏è [CUSTOMER SAGT] üí¨ (Turn 2)');
            } catch (error) {
              logger.error({ error }, 'Failed to generate customer speech (Turn 2)');
            }
          }, 500); // Wait 500ms before responding
        }

        // Customer Turn 3: Confirms after agent acknowledges
        if (this.customerTurnCount === 2 && (data.text.includes('gespeichert') || data.text.includes('notiert') || data.text.includes('Dank'))) {
          this.customerTurnCount++;
          setTimeout(async () => {
            const customerMessage = 'Vielen Dank, auf Wiedersehen';
            logger.info({ text: customerMessage, turn: 3 }, 'üó£Ô∏è Customer speaking (Turn 3)');

            try {
              // Generate TTS audio directly (returns PCM)
              const audioBuffer = await this.ttsProvider.synthesize(customerMessage, 'de');

              // Send via RTP in 20ms chunks (for VAD detection)
              await this.sendAudioInChunks(rtpHandler, audioBuffer);

              // Record the transcript manually
              this.transcriptCount++;

              // Ingest into transcript update service for real-time WebSocket updates
              this.transcriptUpdates.ingest({
                sessionId: this.currentSessionId,
                speaker: 'customer',
                text: customerMessage,
                timestamp: new Date(),
                source: 'CUSTOMER-SAGT',
                isFinal: true  // Mark as final so it broadcasts immediately
              });

              if (this.transcriptVerifier) {
                this.transcriptVerifier.addTranscript({
                  source: 'CUSTOMER-SAGT',
                  speaker: 'customer',
                  text: customerMessage
                });
              }
              logger.info({ text: customerMessage, source: 'CUSTOMER-SAGT', turn: 3 }, 'üó£Ô∏è [CUSTOMER SAGT] üí¨ (Turn 3)');
            } catch (error) {
              logger.error({ error }, 'Failed to generate customer speech (Turn 3)');
            }
          }, 500); // Wait 500ms before responding
        }
      });

      // Listen for customer responses (when customer speaks)
      this.customerPipeline.on('agentResponse', (data) => {
        logger.info({
          speaker: data.speaker,
          text: data.text,
          source: 'CUSTOMER-SAGT'
        }, 'üó£Ô∏è [CUSTOMER SAGT] üí¨');

        // Record in transcript verifier
        if (this.transcriptVerifier) {
          this.transcriptVerifier.addTranscript({
            source: 'CUSTOMER-SAGT',
            speaker: data.speaker,
            text: data.text
          });
        }
      });

      // Audio flow logging disabled to reduce log spam
      // rtpHandler.on('audio', (audioData) => {
      //   // This is audio the customer receives (agent via B2BUA)
      //   logger.debug({
      //     source: 'CUSTOMER-EMPF√ÑNGT',
      //     bytes: audioData.length,
      //     direction: 'Agent ‚Üí B2BUA ‚Üí Customer'
      //   }, 'üì° [CUSTOMER EMPF√ÑNGT AUDIO]');
      // });

      await this.customerPipeline.start();
      logger.info({ callId }, 'üé§ Customer pipeline started');
    });

    this.customerServer.on('callEnded', async ({ callId }) => {
      logger.info({ callId }, 'üì¥ CUSTOMER CALL ENDED');
      if (this.customerPipeline) {
        await this.customerPipeline.stop();
        this.customerPipeline = null;
      }
    });

    this.customerServer.on('callFailed', ({ callId, statusCode, statusText }) => {
      logger.error({ callId, statusCode, statusText }, '‚ùå CUSTOMER CALL FAILED');
    });

    await this.customerServer.start();
    logger.info('‚úÖ Customer Simulator started on port 5062');
  }

  /**
   * Initiate test call from customer to B2BUA
   */
  private async initiateTestCall(): Promise<void> {
    logger.info('');
    logger.info('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');
    logger.info('üé¨ STARTING AUTOMATED TEST CALL');
    logger.info('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');
    logger.info('');

    try {
      // Peer-to-Peer: Call directly to B2BUA on localhost:5060
      const callId = await this.customerServer.initiateOutboundCall({
        toUri: 'sip:b2bua@192.168.188.86:5060',
        fromDisplayName: 'Test Customer'
      });

      logger.info({ callId }, 'üìû Customer initiated call to B2BUA');
      logger.info('');
      logger.info('üîÑ Expected flow:');
      logger.info('   1. Customer (lkschroeder) ‚Üí B2BUA (cwschroeder)');
      logger.info('   2. B2BUA bridges to ‚Üí Agent (pjschroeder)');
      logger.info('   3. 3-Party conference established');
      logger.info('   4. Transcriptions start flowing');
      logger.info('');
      logger.info('‚è±Ô∏è  Call will run for 30 seconds (3 turns), then auto-hangup...');

      // Auto-hangup after 30 seconds (extended for 3 turns)
      setTimeout(async () => {
        logger.info('');
        logger.info('‚è±Ô∏è  30 seconds elapsed, hanging up test call...');
        await this.customerServer.terminateCall(callId);
      }, 30000);

    } catch (error) {
      logger.error({ error }, '‚ùå Failed to initiate test call');
    }
  }

  /**
   * Generate and print verification report
   */
  /**
   * Send audio in 20ms RTP chunks (proper packetization for VAD)
   * Splits TTS buffer into 320-byte chunks (20ms at 8kHz, 16-bit PCM)
   */
  private async sendAudioInChunks(rtpHandler: any, pcmData: Buffer): Promise<void> {
    const CHUNK_SIZE_MS = 20;
    const SAMPLE_RATE = 8000;
    const BYTES_PER_SAMPLE = 2; // 16-bit PCM
    const SAMPLES_PER_CHUNK = (SAMPLE_RATE * CHUNK_SIZE_MS) / 1000;
    const CHUNK_SIZE_BYTES = SAMPLES_PER_CHUNK * BYTES_PER_SAMPLE; // 320 bytes

    logger.debug({
      totalBytes: pcmData.length,
      chunkSize: CHUNK_SIZE_BYTES,
      numChunks: Math.ceil(pcmData.length / CHUNK_SIZE_BYTES)
    }, 'Sending audio in 20ms RTP chunks');

    for (let offset = 0; offset < pcmData.length; offset += CHUNK_SIZE_BYTES) {
      const chunk = pcmData.slice(offset, offset + CHUNK_SIZE_BYTES);
      rtpHandler.sendAudio(chunk);
      await new Promise(resolve => setTimeout(resolve, CHUNK_SIZE_MS));
    }
  }

  private generateVerificationReport(): void {
    if (!this.transcriptVerifier) return;

    logger.info('');
    logger.info('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');
    logger.info('üìä Generating Transcript Verification Report');
    logger.info('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');
    logger.info('');

    // Print all transcripts
    this.transcriptVerifier.printAllTranscripts();

    // Print statistics
    const stats = this.transcriptVerifier.getStatistics();
    logger.info('');
    logger.info('üìà Statistics:');
    logger.info(`   Total Transcripts: ${stats.totalTranscripts}`);
    logger.info(`   Average Length: ${stats.averageLength.toFixed(0)} characters`);
    logger.info('');
    logger.info('   By Source:');
    Object.entries(stats.bySource).forEach(([source, count]) => {
      logger.info(`      ${source}: ${count}`);
    });
    logger.info('');

    // Compare Customer Says vs B2BUA Leg A (should be identical)
    logger.info('üîç Comparing: CUSTOMER-SAGT vs B2BUA-LEG-A');
    logger.info('   (Customer speech should reach B2BUA)');
    this.transcriptVerifier.printComparison('CUSTOMER-SAGT', 'B2BUA-LEG-A');

    // Compare B2BUA vs Agent (should be identical)
    logger.info('üîç Comparing: B2BUA-LEG-A vs AGENT-H√ñRT');
    logger.info('   (B2BUA should forward customer audio to Agent)');
    this.transcriptVerifier.printComparison('B2BUA-LEG-A', 'AGENT-H√ñRT');

    // Compare Agent Says vs Customer Hears (should be identical)
    logger.info('üîç Comparing: AGENT-SAGT vs CUSTOMER-H√ñRT');
    logger.info('   (Agent responses should reach Customer)');
    this.transcriptVerifier.printComparison('AGENT-SAGT', 'CUSTOMER-H√ñRT');

    // Verify audio flow
    const verification = this.transcriptVerifier.verifyAudioFlow();
    logger.info(verification.report);

    // Export transcripts
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const jsonFile = `./test-transcripts-${timestamp}.json`;
    const csvFile = `./test-transcripts-${timestamp}.csv`;

    this.transcriptVerifier.exportToJSON(jsonFile);
    this.transcriptVerifier.exportToCSV(csvFile);

    logger.info('');
    logger.info('üìÅ Transcripts exported:');
    logger.info(`   JSON: ${jsonFile}`);
    logger.info(`   CSV: ${csvFile}`);
    logger.info('');
  }

  async stop(): Promise<void> {
    logger.info('üõë Stopping Test Environment');

    if (this.agentPipeline) {
      await this.agentPipeline.stop();
    }

    if (this.customerPipeline) {
      await this.customerPipeline.stop();
    }

    // Flush any remaining VAD buffers (ensures buffered utterances are emitted)
    for (const [sessionId, buffers] of this.vadBuffers) {
      logger.debug({ sessionId }, 'Flushing VAD buffers for session');
      buffers.legA.flush();
      buffers.legB.flush();
    }
    this.vadBuffers.clear();

    // Flush any pending transcript updates
    this.transcriptUpdates.flushAll();

    // Close WebSocket server
    this.transcriptWebSocket.close();

    await this.b2buaManager.cleanup();
    await this.b2buaServer.stop();
    await this.agentServer.stop();
    await this.customerServer.stop();

    logger.info('‚úÖ Test Environment stopped');
  }
}

// Main test execution
async function runTest() {
  logger.info('');
  logger.info('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');
  logger.info('üß™ B2BUA 3-Party Conference Test');
  logger.info('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');
  logger.info('');

  const testManager = new B2BUATestManager();

  // Graceful shutdown
  process.on('SIGINT', async () => {
    logger.info('');
    logger.info('Received SIGINT, shutting down...');
    await testManager.stop();
    process.exit(0);
  });

  process.on('SIGTERM', async () => {
    logger.info('');
    logger.info('Received SIGTERM, shutting down...');
    await testManager.stop();
    process.exit(0);
  });

  try {
    await testManager.start();

    // Keep alive
    await new Promise(() => {}); // Run forever until Ctrl+C

  } catch (error) {
    logger.error({ error }, '‚ùå Test failed');
    await testManager.stop();
    process.exit(1);
  }
}

// Run
runTest().catch((error) => {
  logger.error({ error }, '‚ùå Unhandled error');
  process.exit(1);
});
